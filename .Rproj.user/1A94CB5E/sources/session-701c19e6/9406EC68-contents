
##############################################################################
#' createCounts2 - extended to fabric model
#' Creates the counts table for the rjpp.
#' @param extree The time tree
#' @param meanbl The output of meanBranches
#' @name createCounts
#' @keywords internal
#' @export
createCountsTable <- function(extree, meanbl) {
  counts <- matrix(ncol = 61, nrow = (nrow(extree$edge) + 1))
  colnames(counts) <- c("branch", "ancNode", "descNode", "nTips", "start", "end", "mid", "orgBL",
                        "meanBL", "medianBL", "modeBL", "quart25", "quart75",
                        "itersScaled", "itersRatescaled", "itersDelta", "itersKappa", "itersLambda", "itersBeta",
                        "pScaled", "pRate", "pDelta", "pKappa", "pLambda", "pBeta",
                        "nScalar", "nRate", "nDelta", "nKappa", "nLambda", "nBeta",
                        "nOrgnScalar", "nOrgnNRate", "nOrgnBRate", "nOrgnDelta", "nOrgnKappa", "nOrgnLambda", "nOrgnBeta",
                        "rangeRate", "lqRate", "uqRate", "meanRate", "medianRate", "modeRate",
                        "rangeDelta", "meanDelta", "medianDelta", "modeDelta",
                        "rangeKappa", "meanKappa", "medianKappa", "modeKappa",
                        "rangeLambda", "meanLambda", "medianLambda", "modeLambda",
                        "rangeBeta", "meanBeta", "medianBeta", "modeBeta", "species")

  counts[ , "branch"] <- c(0:nrow(extree$edge))
  counts[ , "ancNode"] <- c(0, extree$edge[ , 1])
  counts[ , "descNode"] <- c((length(extree$tip.label) + 1), extree$edge[ , 2])
  counts[ , "orgBL"] <- c(0, extree$edge.length)

  if (is.list(meanbl)) {
    counts[ , "meanBL"] <- c(0, meanbl$meanbranches)
    counts[ , "medianBL"] <- c(0, meanbl$medianbranches)
    counts[ , "modeBL"] <- c(0, meanbl$modebranches)
    counts[ , "quart25"] <- c(0, meanbl$quart25)
    counts[ , "quart75"] <- c(0, meanbl$quart75)
  } else {
    counts[ , "meanBL"] <- rep(1, nrow(counts))
    counts[ , "medianBL"] <- rep(1, nrow(counts))
    counts[ , "modeBL"] <- rep(1, nrow(counts))
    counts[ , "quart25"] <- rep(1, nrow(counts))
    counts[ , "quart75"] <- rep(1, nrow(counts))
  }

  hts <- phytools::nodeHeights(extree)
  hts <- round(abs(hts - max(hts)), 4)
  counts[ , "start"] <- c(0, hts[ , 1])
  counts[ , "end"] <- c(0, hts[ , 2])
  counts <- as.data.frame(counts)

  # Deal with the root
  descs <- getDescs(extree, node = counts[1, "descNode"])
  counts[1, "nTips"] <- sum(descs <= length(extree$tip.label))
  counts[1, "mid"] <- 0
  counts[1, "species"] <- paste0(extree$tip.label[order(extree$tip.label)], collapse = ",")

  for (i in 2:nrow(counts)) {
    descs <- getDescs(extree, node = counts[i, "descNode"])
    counts[i, "nTips"] <- sum(descs <= length(extree$tip.label))
    if (counts[i, "nTips"] == 0) {
      counts[i, "nTips"] <- 1
    }
    if (counts[i, "descNode"] <= length(extree$tip.label)) {
      counts[i, "species"] <- extree$tip.label[counts[i, "descNode"]]
    } else {
      tips <- getDescs(extree, counts[i, "descNode"])
      tips <- tips[tips <= length(extree$tip.label)]
      tips <- extree$tip.label[tips]
      counts[i, "species"] <- paste0(sort(tips), collapse = ",")
    }
    counts[i, "mid"] <- mean(c(hts[(i - 1), 1], hts[(i - 1), 2]))
  }

  counts[ , c(14:52)] <- 0
  return(counts)
}


##############################################################################
#' scalarSearch2 - extended to fabric model
#' Searches through the posterior of an RJ continuous model for scalars and
#' returns them.
#' @param rj_output partially processed RJ output.
#' @param counts The counts table.
#' @keywords internal
#' @name scalarSearch
#' @export
scalarSearch <- function(rj_output, counts, fullmrcas) {

  alltypes <- vector(mode = "list", length = nrow(rj_output))
  allmrcas <- vector(mode = "list", length = nrow(rj_output))

  rates <- matrix(rep(1, nrow(counts) * nrow(rj_output)), ncol = nrow(rj_output))
  rownames(rates) <- counts[ , "descNode"]

  # make lists for the origins of deltas etc.
  .tmp <- rep(1, nrow(rj_output))
  Node <- replicate(nrow(counts), as.numeric(paste(.tmp)), simplify = FALSE)
  Branch <- replicate(nrow(counts), as.numeric(paste(.tmp)), simplify = FALSE)
  Delta <- replicate(nrow(counts), as.numeric(paste(.tmp)), simplify = FALSE)
  Lambda <- replicate(nrow(counts), as.numeric(paste(.tmp)), simplify = FALSE)
  Kappa <- replicate(nrow(counts), as.numeric(paste(.tmp)), simplify = FALSE)
  Node_effects <- replicate(nrow(counts), as.numeric(paste(.tmp)), simplify = FALSE)
  LS_Beta <- replicate(nrow(counts), as.numeric(paste(.tmp)), simplify = FALSE)
  names(Node) <- counts[ , "descNode"]
  names(Branch) <- counts[ , "descNode"]
  names(Delta) <- counts[ , "descNode"]
  names(Lambda) <- counts[ , "descNode"]
  names(Kappa) <- counts[ , "descNode"]
  names(Node_effects) <- counts[ , "descNode"]
  names(LS_Beta) <- counts[ , "descNode"]

  print("Searching for scalars...")
  pb <- txtProgressBar(min = 0, max = nrow(rj_output), style = 3)
  for (i in 1:nrow(rj_output)) {
    lastrates <- rj_output[i, !is.na(rj_output[i, ])]

    # If the number of columns is seven, there are no scalars applied this generation.
    if (ncol(lastrates) == 7) {
      nodes <- NA
      scales <- NA
      types <- NA
    } else {

      int <- lastrates[8:length(lastrates)]

      nodes <- unlist(c(int[grep("NodeID*", names(int))]))
      scales <- unlist(c(int[grep("Scale*", names(int))]))
      types <- unlist(c(int[grep("NodeBranch*", names(int))]))
      mrcas <- sapply(nodes, function(x) fullmrcas[fullmrcas$node %in% x, "mrca"])
      alltypes[[i]] <- types
      allmrcas[[i]] <- mrcas

      # Is this for-loop filling the scalar objects? Do I need to make them
      # within this function?
      for (j in 1:length(mrcas)) {
        nm <- paste0(types[j], "[[\"", as.character(mrcas[j]), "\"]]", "[", i, "]")
        eval(parse(text = paste0(nm, "<-", scales[j])))
      }
    }
    setTxtProgressBar(pb, i)
  }

  close(pb)
  res <- list(alltypes = alltypes,
              allmrcas = allmrcas,
              rates = rates,
              Node = Node,
              Branch = Branch,
              Delta = Delta,
              Lambda = Lambda,
              Kappa = Kappa,
              Node_effects = Node_effects,
              LS_Beta = LS_Beta)
  return(res)
}


##########################################
#' meanbranches
#'
#' Calculate the mean branch lengths from a BayesTraits RJ analysis posterior, when topology is fixed.
#' @param reftree A tree that provides the reference topology (ideally the tree the analysis was run on)
#' @param trees The logfile for the rj trees posterior.
#' @export

meanBranches <- function(reftree, trees, burnin = 0, thinning = 1, pbar = FALSE) {

  reftree <- ladderize(reftree)

  if (class(trees) == "multiPhylo") {
    trees <- trees
  } else {
    trees <- read.nexus(trees)
  }
  c
  trees <- trees[seq.int(burnin, length(trees), thinning)]

  #bls <- vector(mode = "numeric", length = length(reftree$edge.length))
  bls <- matrix(nrow = length(reftree$edge.length), ncol = length(trees))

  if (pbar) {
    pb <- txtProgressBar(min = 0, max = length(trees), style = 3)
  }

  for (i in 1:length(trees)) {
    tree <- ladderize(trees[[i]])

    if (sum(reftree$tip.label == tree$tip.label) != length(reftree$tip.label)) {
      stop(paste("Tip labels on tree", i, "do not mactch reference tree"))
    }

    if (sum(reftree$edge == tree$edge) != length(reftree$edge)) {
      stop(paste("Tree", i, "has a different topology to reference tree"))
    }

    bls[ , i] <- tree$edge.length

    if (pbar) {
      setTxtProgressBar(pb, i)
    }
  }

  rangebl <- vector(mode = "numeric", length = nrow(bls))
  quart25 <- vector(mode = "numeric", length = nrow(bls))
  quart75 <- vector(mode = "numeric", length = nrow(bls))
  branchesmean <- vector(mode = "numeric", length(nrow(bls)))
  branchesmedian <- vector(mode = "numeric", length(nrow(bls)))
  branchesmode <- vector(mode = "numeric", length(nrow(bls)))
  for (i in 1:nrow(bls)) {
    branchesmean[i] <- mean(bls[i, ])
    branchesmedian[i] <- median(bls[i, ])
    branchesmode[i] <- modeStat(bls[i, ])
    quarts <- sort(bls[i, ])
    quart25[i] <- quarts[round(length(quarts) * 0.25)]
    quart75[i] <- quarts[round(length(quarts) * 0.75)]
    rangebl[i] <- max(bls[i, ]) - min(bls[i, ])
  }

  meantree <- reftree
  meantree$edge.length <- branchesmean

  res <- list(ogtree = reftree,
              meantree = meantree,
              meanbranches = branchesmean,
              medianbranches = branchesmedian,
              modebranches = branchesmode,
              quart25 = quart25,
              quart75 = quart75,
              rangescalar = rangebl)
  if (pbar) {
    close(pb)
  }
  return(res)
}


##############################################################################
#' rjpp - extended to fabric model
#'
#' A function that takes the output of a kappa, lambda, delta, VRates etc. RJ bayesTraits run and runs post-processing on it.
#' @param rjlog The RJ output of the run - typically suffixed with .VarRates.txt
#' @param tree The time tree the analysis was run on as an object of class "phylo", or the filename of the timetree.
#' @param burnin The burnin (if required) for the mcmc (generally worked out from the other logfile)
#' @param thinning Thinning parameter for the MCMC output - again, worked out from the raw MCMC output logfile.
#' @param meanbranches If true, calculates mean, median and mode branch lengths and returns mean tree.
#' @param ratestable
#' @import phytools pbapply ape
#' @export
#' @name rjpp
rjpp <- function(rjlog, rjtrees, tree, burnin = 0, thinning = 1,
                  meanbranches = TRUE, ratestable = TRUE) {

  pbapply::pboptions(type = "txt", style = 3, char = "=")

  if (class(tree) == "phylo") {
    extree <- ladderize(tree)
  } else {
    extree <- ladderize(read.nexus(tree))
  }

  print("Loading log file.")
  rjout <- loadRJ(rjlog, burnin = burnin, thinning = thinning)

  print("Loading posterior trees.")
  posttrees <- read.nexus(rjtrees)
  posttrees <- posttrees[seq.int(from = burnin + 1, to = length(posttrees), by = thinning)]

  if (meanbranches) {
    print("Calculating mean branch lengths.")
    meanbl <- meanBranches(reftree = extree, trees = posttrees, burnin = burnin,
                           thinning = thinning, pbar = TRUE)
  } else {
    meanbl = FALSE
  }

  rj_output <- rjout$rj_output
  subtrees <- rjout$subtrees
  rjtaxa <- rjout$taxa
  niter <- nrow(rj_output)
  print("Finding taxa.")

  taxa <- pbapply::pblapply(subtrees$node, function(x) getTaxa(x, subtrees = subtrees))

  print("Calculating MRCAs.")
  fullmrcas <- unlist(pbapply::pblapply(taxa, function(x) getMRCAbtr(x , tree = extree, rjtaxa = rjtaxa)))
  fullmrcas <- data.frame(node = subtrees$node, mrca = fullmrcas)

  counts <- createCountsTable(extree, meanbl)

  # Find the scalars.
  all_scalars <- scalarSearch(rj_output, counts, fullmrcas)

  # Calculate cumulative node effects
  print("Calculating cumulative node effects")

  for (i in 1:length(all_scalars$Node)) {
    .tmp <- multiplyNodes(all_scalars$Node[[i]],
                          names(all_scalars$Node)[i],
                          extree,
                          all_scalars$Node_effects)
    all_scalars$Node_effects[names(.tmp)] <- .tmp
  }

  all_scalars$Node_effects <- lapply(1:length(all_scalars$Node_effects),
                                     function(x) all_scalars$Node_effects[[x]] * all_scalars$Branch[[x]])
  names(all_scalars$Node_effects) <- counts[ , "descNode"]

  origins <- list(nodes = do.call(rbind, all_scalars$Node),
                  branches = do.call(rbind, all_scalars$Branch),
                  delta = do.call(rbind, all_scalars$Delta),
                  lambda = do.call(rbind, all_scalars$Lambda),
                  kappa = do.call(rbind, all_scalars$Kappa),
                  rates = do.call(rbind, all_scalars$Node_effects),
                  LS_Beta = do.call(rbind, all_scalars$LS_Beta)
  )

  alltypes <- unlist(all_scalars$alltypes)
  allmrcas <- unlist(all_scalars$allmrcas)

  bs <- table(unlist(allmrcas)[alltypes == "Branch"])
  ns <- table(unlist(allmrcas)[alltypes == "Node"])
  ds <- table(unlist(allmrcas)[alltypes == "Delta"])
  ks <- table(unlist(allmrcas)[alltypes == "Kappa"])
  ls <- table(unlist(allmrcas)[alltypes == "Lambda"])
  be <- table(unlist(allmrcas)[alltypes == "LS_Beta"])

  bstaxa <- counts$descNode %in% names(bs)
  nstaxa <- counts$descNode %in% names(ns)
  dstaxa <- counts$descNode %in% names(ds)
  kstaxa <- counts$descNode %in% names(ks)
  lstaxa <- counts$descNode %in% names(ls)
  betaxa <- counts$descNode %in% names(be)

  counts$nOrgnBRate[bstaxa] <- bs[match(counts$descNode[bstaxa], names(bs))]
  counts$nOrgnScalar[bstaxa] <- counts$nOrgnBRate[bstaxa] + bs[match(counts$descNode[bstaxa], names(bs))]

  counts$nOrgnNRate[nstaxa] <- ns[match(counts$descNode[nstaxa], names(ns))]
  counts$nOrgnScalar[nstaxa] <- counts$nOrgnBRate[nstaxa] + ns[match(counts$descNode[nstaxa], names(ns))]

  counts$nOrgnDelta[dstaxa] <- ds[match(counts$descNode[dstaxa], names(ds))]
  counts$nOrgnScalar[dstaxa] <- counts$nOrgnBRate[dstaxa] + ds[match(counts$descNode[dstaxa], names(ds))]

  counts$nOrgnKappa[kstaxa] <- ks[match(counts$descNode[kstaxa], names(ks))]
  counts$nOrgnScalar[kstaxa] <- counts$nOrgnBRate[kstaxa] + ks[match(counts$descNode[kstaxa], names(ks))]

  counts$nOrgnLambda[lstaxa] <- ls[match(counts$descNode[lstaxa], names(ls))]
  counts$nOrgnScalar[lstaxa] <- counts$nOrgnBRate[lstaxa] + ls[match(counts$descNode[lstaxa], names(ls))]

  counts$nOrgnBeta[betaxa] <- be[match(counts$descNode[betaxa], names(be))]
  counts$nOrgnScalar[betaxa] <- counts$nOrgnBRate[betaxa] + be[match(counts$descNode[betaxa], names(be))]

  # Fill in transformation detail.

  counts[ , "meanDelta"] <- rowMeans(origins$delta)
  counts[ , "medianDelta"] <- apply(origins$delta, 1, median)
  counts[ , "modeDelta"] <-  apply(origins$delta, 1, modeStat)
  counts[ , "rangeDelta"] <- suppressWarnings(apply(origins$delta, 1, max) - apply(origins$delta, 1, min))

  counts[ , "meanKappa"] <- rowMeans(origins$kappa)
  counts[ , "medianKappa"] <- apply(origins$kappa, 1, median)
  counts[ , "modeKappa"] <- apply(origins$kappa, 1, modeStat)
  counts[ , "rangeKappa"] <- suppressWarnings(apply(origins$kappa, 1, max) - apply(origins$kappa, 1, min))

  counts[ , "meanLambda"] <- rowMeans(origins$lambda)
  counts[ , "medianLambda"] <- apply(origins$lambda, 1, median)
  counts[ , "modeLambda"] <- apply(origins$lambda, 1, modeStat)
  counts[ , "rangeLambda"] <- suppressWarnings(apply(origins$lambda, 1, max) - apply(origins$lambda, 1, min))

  counts[ , "meanBeta"] <- rowMeans(origins$LS_Beta)
  counts[ , "medianBeta"] <- apply(origins$LS_Beta, 1, median)
  counts[ , "modeBeta"] <- apply(origins$LS_Beta, 1, modeStat)
  counts[ , "rangeBeta"] <- suppressWarnings(apply(origins$LS_Beta, 1, max) - apply(origins$LS_Beta, 1, min))

  counts[ , "meanRate"] <- rowMeans(origins$rates)
  counts[ , "medianRate"] <- apply(origins$rates, 1, median)
  counts[ , "modeRate"] <- apply(origins$rates, 1, modeStat)
  counts[ , "rangeRate"] <- suppressWarnings(apply(origins$rates, 1, max) - apply(origins$rates, 1, min))

  counts[ , "itersScaled"] <-
    counts[ , "itersRatescaled"] <- apply(origins$rates, 1, function(x) sum(x != 1))
  counts[ , "itersDelta"] <- counts[ , "nOrgnDelta"]
  counts[ , "itersKappa"] <- counts[ , "nOrgnDelta"]
  counts[ , "itersLambda"] <- counts[ , "nOrgnDelta"]
  counts[ , "itersBeta"] <- counts[ , "nOrgnDelta"]

  counts[ , "pScaled"] <-
    counts[ , "pRate"] <- apply(origins$rates, 1, function(x) sum(x != 1)) / niter
  counts[ , "pDelta"] <- counts[ , "nOrgnDelta"] / niter
  counts[ , "pKappa"] <- counts[ , "nOrgnKappa"] / niter
  counts[ , "pLambda"] <- counts[ , "nOrgnLambda"] / niter
  counts[ , "pBeta"] <- counts[ , "nOrgnBeta"] / niter

  counts[ , "nScalar"] <-
    counts[ , "nRate"] <- counts[ , "nOrgnNRate"] + counts[ , "nOrgnBRate"]
  counts[ , "nDelta"] <- counts[ , "nOrgnDelta"]
  counts[ , "nKappa"] <- counts[ , "nOrgnDelta"]
  counts[ , "nLambda"] <- counts[ , "nOrgnDelta"]
  counts[ , "nBeta"] <- counts[ , "nOrgnDelta"]

  # Now just remove anything that is irrelevant (i.e. all values == 1) and then work out
  # what to return.

  counts <- counts[ , apply(counts, 2, function(x) all(x != 1))]
  counts <- counts[ , apply(counts, 2, function(x) all(x != 0))]

  if (meanbranches) {
    meantree <- extree
    meantree$edge.length <- counts[c(2:nrow(counts)) , "meanBL"]
  }

  if (all(sapply(origins$delta, function(x) all(x == 1)))) {
    origins$delta <- NULL
  }

  if (all(sapply(origins$kappa, function(x) all(x == 1)))) {
    origins$kappa <- NULL
  }

  if (all(sapply(origins$lambda, function(x) all(x == 1)))) {
    origins$lambda <- NULL
  }

  if (all(sapply(origins$LS_Beta, function(x) all(x == 1)))) {
    origins$LS_Beta <- NULL
  }

  if (all(sapply(origins$nodes, function(x) all(x == 1)))) {
    origins$nodes <- NULL
  }

  if (all(sapply(origins$branches, function(x) all(x == 1)))) {
    origins$branches <- NULL
  }

  if (all(sapply(origins$rates, function(x) all(x == 1)))) {
    origins$rates <- NULL
  }

  if (meanbranches) {
    res <- list(data = counts, niter = niter, meantree = meantree)
  } else {
    res <- list(data = counts, niter = niter)
  }

  if (!is.null(origins$rates)) {
    scalars <- list(rates = origins$rates)
    origins$rates <- NULL
    res <- c(res, list(scalars = scalars))
  }

  res <- c(res, list(origins = origins))

  return(res)
}




#' ggAutoCor
#'
#' Makes an autocorrealtion plot using ggplot2 - which looks nicer than the
#' core R plot functions.
#' @param dat The vector of the paramater you want to see an autocorrelation plot for.
#' @param conf The confidence level you want to see the limits for.
#' @param max.lag Maximum lag
#' @param min.lag Minimum lag

ggAutoCor <- function(output, pars, conf, max.lag = NULL, min.lag = 0, title = "") {
  dat <- output[ ,pars]
  confline <- qnorm((1 - conf)/2)/sqrt(length(dat))
  x <- acf(dat, plot = FALSE, lag.max = max.lag)
  xacf <- with(x, data.frame(lag, acf))

  if (min.lag > 0) {
    xacf <- xacf[-seq(1, min.lag), ]
  }

  sig <- (abs(xacf[ ,2]) > abs(confline)) ^2
  z <- ggplot(xacf, aes(x = lag, y = acf)) +
    geom_bar(color = "darkgray", stat = "identity", position = "identity", fill = "dodgerblue") +
    geom_hline(yintercept = -confline, color = "blue", size = 0.2) +
    geom_hline(yintercept = confline, color = "blue", size = 0.2) +
    geom_hline(yintercept = 0, color = "red", size = 0.2) +
    ggtitle(paste(pars, title))

  return(z)
}

#' btmcmc
#'
#' Returns the full mcmc object from a BayesTraits log file. This
#' is used inside plot functions and so on, but might be useful for
#' other MCMC manipulations and so on.
#' @param logfile The name of the logfile of the BayesTraits analysis.
#' @param thinning Thinning parameter for the posterior - defaults to 1 (all samples). 2 uses every second sample, 3 every third and so on.
#' @param burnin The number of generations to remove from the start of the chain as burnin. Use if the chain has not reached convergence before sampling began.
#' @return A data frame containing the sample from the BayesTrait mcmc.

btmcmc <- function(logfile, thinning = 1, burnin = 0) {

  raw <- readLines(logfile)
  model <- gsub(" ", "", raw[2])
  output <- do.call(rbind, strsplit(raw[grep("\\bIteration\\b", raw):length(raw)], "\t"))
  colnames(output) <- output[1, ]
  output <- output[c(2:nrow(output)), ]
  output <- data.frame(output, stringsAsFactors = FALSE)

  for (i in 1:ncol(output)) {
    if (colnames(output)[i] != "Model.string" && colnames(output)[i] != "Dep...InDep") {
      output[ ,i] <- as.numeric(output[ ,i])
    }

  }
  output <- output[seq.int(burnin, nrow(output), thinning), ]
  return(output)
}

##############################################################################
#' rateShifts
#' Generates the edge colours to colour edges by total rate.
#' @name rateShifts
#' @keywords internal
rateShifts <- function(PP, threshold, gradientcols, colour) {
  percscaled <- apply(PP$scalars[[1]][2:nrow(PP$scalars[[1]]), ], 1, function(x) sum(x != 1)) / PP$niter

  if (threshold == 0) {
    edge.cols <- plotrix::color.scale(percscaled, extremes = gradientcols, na.color = NA)

  } else if (threshold > 0) {
    nodes <- as.numeric(names(percscaled[percscaled >= threshold]))
    edge.cols <- rep("black", nrow(PP$meantree$edge))
    edge.cols[PP$meantree$edge[ , 2] %in% nodes] <- colour
  } else if (threshold == "relative") {
    edge.cols <- plotrix::color.scale(log(PP$data$meanRate[2:nrow(PP$data)]), extremes = gradientcols, na.color = NA)
  }
  return(edge.cols)
}

##############################################################################
#' transShifts
#' Generates the node labels, edge.colours and transparencies to plot the
#' location of transformations in a posterior.
#' @name transShifts
#' @keywords internal

transShifts <- function(PP, threshold, cl, tree, transparency, relativetrans,
                        nodescaling, colour, nodecex) {
  if (threshold == "relative") {
    stop("Relative threshold not valid for total rate scalars.")
  }

  if (threshold == 0) {
    threshold <- 1 / PP$niter
  }


  nodes <- PP$data$descNode[which((PP$data[ , cl] / PP$niter) >= threshold)]


  pprobs <- PP$data[which((PP$data[ , cl] / PP$niter) >= threshold) , cl] / PP$niter

  if (length(nodes) == 0) {
    stop("No scalars above threshold.")
  }

  if (transparency) {
    alphas <- pprobs
  } else {
    alphas <- rep(1, length(nodes))
  }

  if (relativetrans) {
    for (i in 1:length(alphas)) {
      alphas[i] <- (alphas[i] - min(alphas)) / (max(alphas) - min(alphas))
    }
  }

  col <- vector(mode = "character", length = length(nodes))

  col <- sapply(1:length(alphas),
                function(x) makeTrans(colour = colour, alpha = alphas[x]))

  if (nodescaling) {
    nodecex = nodecex * pprobs
  }

  if (cl == "nOrgnBRate") {
    nodes <- which(tree$edge[ , 2] %in% nodes)
  }

  list(nodes = nodes, colours = col, alphas = alphas, nodecex = nodecex)
}

################################################################################
#' plotShifts
#'
#' Plots the locations of the origins of scalars from the postprocessor output of bayestraits.
#' CURRENTLY WORKS ONLY FOR DELTAS.
#' @param PP The psotprocessor (localscalrPP) output.
#' @param scalar The scalar to find and plot from the post processor - delta/lambda/kappa/node/branch
#' @param threshold Threshold of probability in posterior to display deltas for, defaults to zero (i.e. shows all deltas shaded proportionally to the posterior probability)
#' @param colour The colour to use for the node circles
#' @param scaled Plot the original tree (scaled = "time", the default), or the mean/sclaed tree (scaled = "mean") or plot the tree scaled only by scalars present above the threshold (scaled = "threshold")?
#' @param nodecex The scaling factor for the size of the node circles
#' @param tips Show tip labels?
#' @param scalebar Include scale bar?
#' @param measure When plotting "siginficant" tree, what measure of the parameter? Median (default), mode or mean.
#' @param exludeones If plotting according to a threshold of significance, should 1s (i.e. no scalar) be excluded from the posterior when calculating average scalar?
#' @param relativetrans If TRUE (defaults to FALSE) the scale of transparency will go from the threshold (totally transparent) to the maximum presence (full opacity).
#' @param nodescaling Scale node symbols according to posterior probability of shift (default).
#' @param transparency Adjust node symbol transparency according to posterior probability? Defaults to FALSE.
#' @param gradientcols A vector of two colours - the min and max colours used when colouring the tree according to percentage time rate scaled (when threshold = 0) or using rate.edges.
#' @param rate.edges Takes a numeric value between 0 and 1. If NULL (default) then node shapes are plotted for a transformation. If equal to zero then node shapes are plotted along with a colour gradient on the branches for rates (if in the posterior), and if set to a threshold then the branches are coloured black/red for whether there is a scalar over the threshold (red) along with node scalars.
#' @param shp The shape of the node markers (uses the usual pch index).
#' @name plotShifts
#' @import plotrix
#' @export
#'
plotShifts <- function(PP, scalar, threshold = 0, threshold2 = 0, nodecex = 2, scaled = "time", scalebar = TRUE,
                       measure = "median", excludeones = FALSE, relativetrans = FALSE, nodescaling = TRUE,
                       transparency = FALSE, gradientcols = c("dodgerblue", "firebrick1"), rate.edges = NULL,
                       colour = "red", colour2 = "green",  shp = 21, tips = FALSE, ...) {

  if (scalar == "delta") {
    cl <- "nOrgnDelta"
    mode <- "trans"
  } else if (scalar == "kappa") {
    cl <- "nOrgnKappa"
    mode <- "trans"
  } else if (scalar == "lambda") {
    cl <- "nOrgnLambda"
    mode <- "trans"
  } else if (scalar == "branch") {
    cl <- "nOrgnBRate"
    mode <- "trans"
  } else if (scalar == "node") {
    cl <- "nOrgnNRate"
    mode <- "trans"
  } else if (scalar == "rate") {
    cl <- "nOrgnScalar"
    mode <- "rate"
  } else if (scalar == "nodebranch") {
    cl <- c("nOrgnNRate", "nOrgnBRate")
    mode <- "doubletrans"
  }

  if (scaled == "time") {
    tree <- PP$meantree
    tree$edge.length <- PP$data$orgBL[2:nrow(PP$data)]
  } else if (scaled == "mean") {
    tree <- PP$meantree
  } else if (scaled == "median") {
    tree <- PP$meantree
    tree$edge.length <- PP$data$medianBL[2:nrow(PP$data)]
  } else if (scaled == "mode") {
    tree <- PP$meantree
    tree$edge.length <- PP$data$modeBL[2:nrow(PP$data)]
  } else if (scaled == "threshold") {
    if (mode == "rate") {
      tree <- tree
    } else {
      # tree <- shiftScaledTree() #### IN DEV.
    }
  }

  if (mode == "trans") {
    edge.cols <- "black"

    if (isDefined(rate.edges)) {
      try(if(is.null(PP$scalars)) stop("No rate scalars in posterior output."))
      edge.cols <- rateShifts(PP, threshold = rate.edges, gradientcols, colour)
    }

    node_info <- transShifts(PP, threshold, cl, tree, transparency, relativetrans,
                             nodescaling, colour, nodecex)

  } else if (mode == "doubletrans") {
    edge.cols <- "black"

    if (isDefined(rate.edges)) {
      try(if(is.null(PP$scalars)) stop("No rate scalars in posterior output."))
      edge.cols <- rateShifts(PP, threshold = rate.edges, gradientcols, colour)
    }

    node_info <- transShifts(PP, threshold, cl[1], tree, transparency, relativetrans,
                             nodescaling, colour, nodecex)

    branch_info <- transShifts(PP, threshold2, cl[2], tree, transparency, relativetrans,
                               nodescaling, colour2, nodecex)

  } else if (mode == "rate") {
    edge.cols <- rateShifts(PP, threshold, gradientcols, colour)
  }

  plotPhylo(tree, tips = tips, edge.col = edge.cols, scale = scalebar, ...)

  if (scalar != "rate") {
    if (scalar == "branch") {
      edgelabels(edge = node_info$nodes, bg = node_info$col,
                 pch = shp, cex = node_info$nodecex)
    } else if (scalar == "nodebranch") {
      nodelabels(node = node_info$nodes, bg = node_info$col,
                 pch = shp, cex = node_info$nodecex)
      edgelabels(edge = branch_info$nodes, bg = branch_info$col,
                 pch = shp, cex = branch_info$nodecex)
    } else {
      nodelabels(node = node_info$nodes, bg = node_info$col,
                 pch = shp, cex = node_info$nodecex)
    }
  }
}


##############################################################################
#' loadRJ
#'
#' Returns the full mcmc object from a BayesTraits log file. This
#' is used inside plot functions and so on, but might be useful for
#' other MCMC manipulations and so on.
#' @param logfile The name of the logfile of the BayesTraits analysis.
#' @return A list containing the taxa translation table, all possible subtrees a scalar can occur on, and a data frame of the rj model configuration.
#' @export
loadRJ <- function(logfile, burnin = 0, thinning = 1) {

  raw <- readLines(logfile)
  rawhead <- strsplit(raw[1:(grep("\\bIt*\\b", raw) -1)], "\t")
  rawtail <- strsplit(raw[grep("\\bIt*\\b", raw):length(raw)], "\t")
  nms1 <- rawtail[[1]][1:7]
  nms2 <- rawtail[[1]][8:length(rawtail[[1]])]
  nms2 <- gsub(" ", "", nms2)
  nms2 <- gsub("/", "", nms2)

  for (i in 1:length(rawtail)) {
    if (length(rawtail[[i]]) == 7) {
      names(rawtail[[i]]) <- nms1
    } else {
      len <- length(rawtail[[i]][8:length(rawtail[[i]])])
      end <- vector(mode = "character", length = len)

      st <- 1
      ed <- 4
      for (j in 1:(len/4)) {
        end[c(st:ed)] <- paste(nms2, j, sep = "_")
        st <- st + 4
        ed <- ed + 4
      }
      nms <- c(nms1, end)
      names(rawtail[[i]]) <- nms
    }
  }

  tipnum <- rawhead[[1]]
  taxatrans <- do.call(rbind, rawhead[c(1:tipnum+1)])
  subtreestart <- nrow(taxatrans) + 3
  subtrees <- rawhead[subtreestart:length(rawhead)]

  for (i in 1:length(subtrees)) {
    names(subtrees[[i]]) <- c(1:length(subtrees[[i]]))
  }

  output <- do.call(smartBind, rawtail)
  output <- output[seq.int(burnin, nrow(output), thinning), ]
  output <- data.frame(output[2:nrow(output), ], stringsAsFactors = FALSE)
  subtrees <- do.call(smartBind, subtrees)
  subtrees <- data.frame(subtrees, stringsAsFactors = FALSE)
  colnames(subtrees)[c(1:2)] <- c("node", "bl")

  res <- list(taxatrans, subtrees, output)
  names(res) <- c("taxa", "subtrees", "rj_output")
  return(res)
}

########################################################
#' smartBind
#'
#' A function that will rbind vectors of different lengths and return a matrix, provided each vector element is named.
#' @param A bunch of vectors.
#' @export
#' @examples
#' do.call(smartRbind, list.of.vectors)

smartBind <- function (...) {
  # from GSee http://stackoverflow.com/questions/17308551/do-callrbind-list-for-uneven-number-of-column
  dargs <- list(...)

  if (!all(vapply(dargs, is.vector, TRUE)))
    stop("all inputs must be vectors")

  if (!all(vapply(dargs, function(x) !is.null(names(x)), TRUE)))
    stop("all input vectors must be named.")

  all.names <- unique(names(unlist(dargs)))
  out <- do.call(rbind, lapply(dargs, `[`, all.names))
  colnames(out) <- all.names
  out
}


##############################################################################
#' modeStat
#' Calculate the mode.
#' @name modeStat
#' @keywords internal

modeStat <- function(x, log = FALSE)
{
  if (length(x) < 2) {
    return("NA")
  }

  if (all(x == x[1])) {
    return(x[1])
  }

  if (log == TRUE) {
    dens <- density(log(x))
    mode.tmp <- dens$x[which(dens$y == max(dens$y))]
    mode <- exp(mode.tmp)
  } else {
    dens <- density(x)
    mode <- dens$x[which(dens$y == max(dens$y))]
  }
  return(mode)
}

#' Multiple plot function
#'
#' ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
#' HFG: From http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_%28ggplot2%29/.
#' If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
#' then plot 1 will go in the upper left, 2 will go in the upper right, and
#' 3 will go all the way across the bottom.
#' @param cols   Number of columns in layout
#' @param layout A matrix specifying the layout. If present, 'cols' is ignored.
#' @param plotlist A list of plot objects (as opposed to individual objects)
#' @examples
#' multiplot(plot1, plot2, plot3, plot4, cols = 2)
#' all.plots <- list(plo1, plot2, plot3, plot4)
#' multiplot(plotlist = all.plots, cols = 2)

multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                     ncol = cols, nrow = ceiling(numPlots/cols))
  }

  if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

##############################################################################
#' multiplyNodes
#' Works out the cumulative effect of linear scalars on branches per iteration
#' @param scales A vector of scalars for a node
#' @param name The name of the node
#' @param tree The time tree
#' @param Node_effects A list, one element per node, to fill with the cumulative scalars
#' @name multiplyNodes
#' @keywords internal
multiplyNodes <- function(scales, name, tree, Node_effects) {
  # get descendents
  descs <- c(getDescs(tree, name), as.numeric(name))
  .tmp <- lapply(Node_effects[as.character(descs)], function(x) x * scales)
  return(.tmp)
}

#' compPosts
#'
#' Compares histograms of one or more parameters from the same output file, or one parameter from one or more output files.
#'
#' @param logs The name of the trait data file on which BayesTraits was run, or a vector of >1 names if comparing between >1 logs.
#' @param pars A vector containing the names of two parameters to be compared. Must be a single parameter if comparing between two logs. Can
#' be subsetted from the output of getParams().
#' @param thinning Thinning parameter for the posterior - defaults to 1 (all samples). 2 uses every second sample, 3 every third and so on.
#' @param burnin The number of generations to remove from the start of the chain as burnin.
#' @keywords plot posterior histogram distribution compare
#' @export
#' @examples
#' plotPosterior(cool-data.txt, c("Lh", "Alpha 1"))
#' plotPosterior(cool-data.txt, params[c(1:2)])

compPosts <- function(logs, pars, thinning = 1, burnin = 0, alpha = 0.5, fontsize = 3) {

  if (length(logs) == 1) {
    output <- btmcmc(logs, thinning = thinning, burnin = burnin)
  } else {
    output <- lapply(logs, btmcmc, thinning = thinning, burnin = burnin)
  }

  if (length(logs) == 1) {
    ps <- list()

    for (i in 1:length(pars)) {
      ps[[i]] <- data.frame(d = output[ ,pars[i]], id = pars[i])
    }

    p <- do.call(rbind, ps)
  } else {
    ps <- list()

    for (i in 1:length(output)) {
      ps[[i]] <- data.frame(d = output[[i]][ ,pars], id = logs[i])
    }

    p <- do.call(rbind, ps)
  }

  bwidth <- 3.5 * sd(p$d) * length(p$d) ^ -(1/3)
  ret <- ggplot(p, aes(x = d, fill = id)) +
    geom_histogram(binwidth = bwidth, alpha = alpha, position = "identity") +
    theme(legend.text = element_text(size = fontsize))

  return(ret)
}

#' compareStones
#'
#' A function to extract the marginal likelihood from the stepping
#' stone sampler output of two BayesTraits runs, and work out the
#' log Bayes Factors.
#' @param comp The name of the stepping stones log file of the more complex of the two BayesTraits models.
#' @param simp The name of the stepping stone log file of the more simple of the two BayesTraits models.
#' @return The log Bayes factor of the comparison between the more complex and the more simple model.
#' @keywords hypothesis testing significance Bayes factors stepping stone
#' @export
#' @examples
#' compareStones("complex.model.stones.log.txt", "simple.model.stones.log.txt")

compareStones <- function(comp, simp) {
  raw.comp <- readLines(comp)
  raw.simp <- readLines(simp)

  marg.lh.comp <-  as.numeric(strsplit(raw.comp[length(raw.comp)], "\t")[[1]][2])
  marg.lh.simp <- as.numeric(strsplit(raw.simp[length(raw.simp)], "\t")[[1]][2])

  logBF <- 2 * (marg.lh.comp - marg.lh.simp)
  evidence <- vector()

  if (logBF < 2) {
    evidence <- "Weak evidence for complex model"
  } else if (logBF >= 2 && logBF < 5) {
    evidence <- "Positive evidence for complex model"
  } else if (logBF >= 5 && logBF <= 10) {
    evidence <- "Strong evidence for complex model"
  } else if (logBF > 10) {
    evidence <- "Very strong evidence for complex model"
  }

  names(logBF) <- "log BF"
  return(logBF)
}

################################################################################
#' findShifts
#'
#' Returns the node numbers of nodes that have been scaled in the posterior over the specified threshold. Works for rate scalars, and transformations. Also can return branch scalars, if rates. Only looks at the placement of scalars, not the cumulative downstream effects of scalars.
#' @param PP The psotprocessor (localscalrPP) output.
#' @param scalar The scalar to find and plot from the post processor - delta/lambda/kappa/node/branch. If rate then the nodes and branches that are given scalars over the threshold are returned.
#' @param threshold Threshold of probability in posterior to display deltas for, defaults to zero (i.e. shows all deltas shaded proportionally to the posterior probability)
#' @name findShifts
#' @export

findShifts <- function(PP, scalar, threshold) {
  if (scalar == "delta") {
    cl <- "nOrgnDelta"
    mode <- "trans"
  } else if (scalar == "kappa") {
    cl <- "nOrgnKappa"
    mode <- "trans"
  } else if (scalar == "lambda") {
    cl <- "nOrgnLambda"
    mode <- "trans"
  } else if (scalar == "branch") {
    cl <- "nOrgnBRate"
    mode <- "trans"
  } else if (scalar == "node") {
    cl <- "nOrgnNRate"
    mode <- "trans"
  } else if (scalar == "rate") {
    cl <- "nOrgnScalar"
    mode <- "rate"
  }

  if (mode == "rate") {
    output <- findRateShifts(PP, threshold)
  } else if (mode == "trans") {
    if (type == "branch") {
      stop("Branch scalars are not valid for transformations.")
    }
    output <- findTransShifts(PP, threshold, cl)
  }

  return(output)
}

################################################################################
#' findRateShifts
#'
#' Return the node or branch numbers with rate scalars applied over the threshold number.
#' @param PP an output from rjpp
#' @param threshold the threshold over which scalars are considered interesting.
#' @param type Node or branch
#' @keywords internal
#' @name findRateShifts

findRateShifts <- function(PP, threshold, type) {

  if (threshold == 0) {
    threshold <- 1 / PP$niter
  }

  nodes <- PP$data$descNode[which((PP$data[ , "nOrgnNRate"] / PP$niter) >= threshold)]
  branches <- PP$data$descNode[which((PP$data[ , "nOrgnBRate"] / PP$niter) >= threshold)]
  edges <- which(tree$edge[ , 2] %in% branches)

  return(list(nodes = nodes, edges = edges))
}

################################################################################
#' findTransShifts
#'
#' return the node numbers that have had transformations applied over a given threshold.
#' @param PP an output from rjpp
#' @param threshold The threshold over which transformations are considered "significant".
#' @keywords internal
#' @name findTransShifts

findTransShifts <- function(PP, threshold, cl) {
  if (threshold == 0) {
    threshold <- 1 / PP$niter
  }

  nodes <- PP$data$descNode[which((PP$data[ , cl] / PP$niter) >= threshold)]
  return(nodes)
}

#' getParams
#'
#' This functions returns the names of the estimated parameters from a BayesTraits
#' analysis logfile for input into plotting and other analysis functions.
#' @param logfile The name of the trait data file on which BayesTraits was run.
#' @return A vector of the parameter names of the model logfile results from.
#' @keywords parameters
#' @export
#' @examples
#' getParams("cool-data.txt")

getParams <- function(logfile) {
  raw <- readLines(logfile)
  params <- do.call(rbind, strsplit(raw[grep("\\bIteration\\b", raw):length(raw)], "\t"))[1, ]
  params <- params[c(2:length(params))]
  params <- chartr(" ()^-", ".....", params)
  return(params)
}

##########################################################################################
#' getDescs
#'
#' A function to get all descendant nodes from a given node, or vector of tip labels.
#' @param tree A tree of class phylo
#' @param node Either a single node, or a vector of tip labels
#' @name getDescs
#' @export

getDescs <- function(tree, node, nds = NULL) {

  if (length(node) > 1) {
    node <- getMRCA(tree, node)
  }

  if (is.null(nds)) {
    nds <- vector()
  }

  dtrs <- tree$edge[which(tree$edge[ , 1] == node), 2]
  nds <- c(nds, dtrs)
  now <- which(dtrs >= length(tree$tip))

  if (length(now) > 0) {

    for (i in 1:length(now)) {
      nds <- getDescs(tree, dtrs[now[i]], nds)
    }

  }
  return(nds)
}

##########################################################################################
#' getPL
#' Gets the path length from the root to the position of a particular node.
#' @export
#' @name getPL
#' @keywords internal

getPL <- function(tree, startnode = NA, node) {

  # Get all paths for this tree
  allpaths <- ape::nodepath(tree)

  # get all paths containing this node
  if(node > ape::Ntip(tree)) {

    paths <- allpaths[grepl(node, allpaths)]

  } else {

    paths <- allpaths[[node]]

  }

  # If the terminal node we care about is not a terminal, we want to remove the branches after our node
  if(node > ape::Ntip(tree)) {

    paths <- lapply(paths, function(x) x <- x[x > ape::Ntip(tree)])
    path <- unlist(unique(lapply(paths, function(x) x <- x[x <= node])))

  } else {

    path <- unlist(unique(paths))

  }
  # If the startnode is not NA, then we want to trim the paths.
  if(!is.na(startnode)) {

    while(path[1] != startnode) {
      path <- path[-1]
    }

    path <- path[-1]
  }
  # Remove the start node [ otherwise it puts the leading branch in there too ]
  # get the path length

  branches <- which(tree$edge[,2] %in% path)
  distance <- sum(tree$edge.length[branches])
  return(distance)
}

##########################################################################################
#' getTipNames
#'
#' A function to get the names of the descendant tips from a given node of a tree.
#' @param tree A tree of class phylo.
#' @param node The node number of interest.
#' @export

getTipNames <- function(tree, node) {
  descs <- getDescs(tree, node)
  descs <- descs[descs <= length(tree$tip.label)]
  tree$tip.label[descs]
}

##########################################################################################
#' getTaxa
#'
#' This gets the taxa names of a particular subtree from a list of all subtrees comprising a full tree.
#' @param subtrees A list of subtrees, as written by BayesTraits, and read in during post-processing
#' @param node The node number of interest.
#' @name getTaxa
#' @keywords internal

getTaxa <- function(x, subtrees) {
  taxa <- subtrees[subtrees$node == x, ]
  taxa <- taxa[ , !is.na(taxa)]
  taxa <- taxa[c(4:length(taxa))]
  return(as.numeric(unlist(taxa)))
}

##########################################################################################
#' getMRCAbtr
#'
#' This an extension of apes's getMRCA that enables the return of a tip, or an MRCA. Translates taxa codes (BayesTraits) to proper tip labels. Useful only in post-processing.
#' @param x A vector of taxa names
#' @param tree A phylogeny of class "phylo" (generally the time tree used as input to BayesTraits)
#' @param rjtaxa The taxa translations as output from BayesTraits
#' @name getMRCAbtr
#' @keywords internal

getMRCAbtr <- function(x, tree, rjtaxa) {
  if (length(x) == 1) {
    mrca <- which(tree$tip.label == rjtaxa[rjtaxa[ , 1] %in% x, 2])
  } else {
    mrca <- ape::getMRCA(tree, rjtaxa[rjtaxa[ , 1] %in% x, 2])
  }
  return(mrca)
}

#' ggDens
#'
#' Make a density plot for an MCMC parameter using ggplot2.
#' @param dat The vector of paramater you want to see an autocorrelation plot for.

ggDens <- function(output, pars, title = ""){
  dat <- output[ ,pars]
  bw <- 1.06 * min(sd(dat), IQR(dat)/1.34) * length(dat)^-0.2
  z <- ggplot(data.frame(p = dat), aes(x = p)) +
    geom_density(alpha = 0.3, fill = "dodgerblue", binwidth = bw) +
    ggtitle(paste(pars, title))

  return(z)
}

#' ggAutoCor
#'
#' Makes an autocorrealtion plot using ggplot2 - which looks nicer than the
#' core R plot functions.
#' @param dat The vector of the paramater you want to see an autocorrelation plot for.
#' @param conf The confidence level you want to see the limits for.
#' @param max.lag Maximum lag
#' @param min.lag Minimum lag

ggAutoCor <- function(output, pars, conf, max.lag = NULL, min.lag = 0, title = "") {
  dat <- output[ ,pars]
  confline <- qnorm((1 - conf)/2)/sqrt(length(dat))
  x <- acf(dat, plot = FALSE, lag.max = max.lag)
  xacf <- with(x, data.frame(lag, acf))

  if (min.lag > 0) {
    xacf <- xacf[-seq(1, min.lag), ]
  }

  sig <- (abs(xacf[ ,2]) > abs(confline)) ^2
  z <- ggplot(xacf, aes(x = lag, y = acf)) +
    geom_bar(color = "darkgray", stat = "identity", position = "identity", fill = "dodgerblue") +
    geom_hline(yintercept = -confline, color = "blue", size = 0.2) +
    geom_hline(yintercept = confline, color = "blue", size = 0.2) +
    geom_hline(yintercept = 0, color = "red", size = 0.2) +
    ggtitle(paste(pars, title))

  return(z)
}

#' ggRunmean
#'
#' Make a running mean plot for an MCMC parameter using ggplot2.
#' @param dat The vector of the paramater you want to see an autocorrelation plot for.

ggRunmean <- function(output, pars, window.size = 10, title = "") {
  dat <- output[ , pars]
  windows <- seq.int(window.size, length(dat), window.size)

  if (windows[length(windows)] != length(dat)) {
    windows <- c(windows, length(dat))
  }

  means <- vector(mode = "numeric", length = length(windows))

  for (i in 1:length(windows)) {
    means[i] <- mean(dat[c((windows[i] - (window.size -1)):windows[i])])
  }

  z <- ggplot(data.frame(Window = c(1:length(windows)), mean = means), aes(x = Window, y = mean)) +
    geom_point(color = "dodgerblue") +
    ggtitle(paste(pars, title)) +
    geom_smooth(method = "lm", formula = y ~ x)
  return(z)
}

##############################################################################
#' localRate
#'
#' A function that transforms branch lengths according to a scalar.
#' @param tree A tree of class phylo.
#' @param node A node number describing the clade to be transformed.
#' @param scalar The multiplier that rate is increased by in the clade specified by node.
#' @keywords internal

localRate <- function(tree, node, scalar) {
  descs <- getDescs(tree, node)
  descs <- c(node, descs)
  trans.edges <- which(tree$edge[ ,2] %in% descs)
  tree$edge.length[trans.edges] <- scalar * tree$edge.length[trans.edges]
  return(tree)
}

##############################################################################
#' localLambda
#'
#' A function that transforms a tree according to lambda, or a portion of a tree according to lambda.
#' @param tree A tree of class phylo.
#' @param node A node number describing the clade(s) to be transformed.
#' @param lambda The value or values of lambda by which to transform the specified clade(s).
#' @keywords internal

localLambda <- function(tree, node, lambda) {
  descs <- getDescs(tree, node)
  trans.edges <- which(tree$edge[ ,2] %in% descs & tree$edge[ ,2] > length(tree$tip.label))
  ht1 <- phytools::nodeHeights(tree)
  tree$edge.length[trans.edges] <- lambda * tree$edge.length[trans.edges]
  ht2 <- phytools::nodeHeights(tree)
  tree$edge.length[-trans.edges] <- tree$edge.length[-trans.edges] + ht1[-trans.edges, 2] - ht2[-trans.edges, 2]
  return(tree)
}

##############################################################################
#' localKappa
#'
#' A function that transforms branch lengths according to Kappa.
#' @param tree A tree of class phylo.
#' @param node A node number describing the clade to be transformed.
#' @param kappa The multiplier that rate is increased by in the clade specified by node.
#' @keywords internal

# TODO(hfg): Add rescale option.

localKappa <- function(tree, node, kappa, rescale = TRUE) {
  descs <- getDescs(tree, node)
  descs <- c(node, descs)
  trans.edges <- which(tree$edge[ ,2] %in% descs)
  originalsum <- sum(tree$edge.length[trans.edges])
  res <- tree
  res$edge.length[trans.edges] <- tree$edge.length[trans.edges] ^ kappa

  if (rescale) {
    newsum <- sum(res$edge.length[trans.edges])
    ratio <- originalsum / newsum
    res$edge.length[trans.edges] <- res$edge.length[trans.edges] * ratio
  }

  return(res)
}

##############################################################################
#' localDelta
#'
#' A function that transforms a tree according to lambda, or a portion of a tree according to lambda.
#' @param tree A tree of class phylo.
#' @param node A node number describing the clade(s) to be transformed.
#' @param delta The value or values of lambda by which to transform the specified clade(s).
#' @name localDelta
#' @keywords internal

# TODO(hfg): Add rescale option. Find the original root to tip length of the clade, divide it by the new root to tip length, and then multiply the new branch lengths by that.

localDelta <- function(tree, node, delta, rescale = TRUE) {
  descs <- getDescs(tree, node)
  tips <- tree$tip.label[descs[descs <= length(tree$tip.label)]]

  # Make a subtree by using drop.tip, and keep a copy of the edge matrix
  # for comparison later on...

  subtree <- drop.tip(tree, tree$tip.label[!tree$tip.label %in% tips])

  n <- Ntip(subtree)
  hts <- data.frame(phytools::nodeHeights(subtree))
  colnames(hts) <- c("start", "end")
  T <- max(hts[,1])

  # Into heights I need to get the path length (the length from the root of the tree to that
  # node) and the branch length (which ought to be the end - the start)

  hts$t <- T - hts$end
  hts$bl <- hts$end - hts$start

  bls <- (hts$start + hts$bl) ^ delta - hts$start ^ delta

  subtree$edge.length <- bls

  if (rescale) {
    scale <- T ^ delta
    subtree$edge.length <- (subtree$edge.length / scale) * T
  }

  tree$edge.length[tree$edge[ , 2] %in% descs] <- subtree$edge.length
  res <- tree
  return(res)
}

##############################################################################
#' localEB
#'
#' A function to transform a tree according to the exponential change/Early Burst model of Harmon et al 2010
#' @param tree A tree object of class phylo
#' @param node The node that the transformation should be applied at (includes all branches and nodes downstream of here).
#' @param a The EB parameter for the transformation.
#' @param rescale Rescale the tree after transformation? Defailts to TRUE.
#' @keywords internal

localEB <- function(tree, node, a, rescale = TRUE) {
  print("Warning! This might be wrong (24/02/2017)")
  descs <- getDescs(tree, node)
  descs <- c(descs, node)
  trans.edges <- which(tree$edge[ ,1] %in% descs & tree$edge[ ,1] > length(tree$tip.label))
  bls <- tree$edge.length[trans.edges]
  times <- ape::branching.times(tree)
  times <- times[names(times) %in% descs]
  maxt <- max(times)
  originalsum <- sum(tree$edge.length[trans.edges])
  res <- tree
  for (i in trans.edges) {
    branch <- res$edge.length[i]
    age <- times[which(names(times) == res$edge[i, 1])]
    t1 <- max(times) - age
    t2 <- t1 + branch
    res$edge.length[i] <- (exp(a * t2) - exp(a * t1))/(a)
  }

  if (rescale) {
    newsum <- sum(res$edge.length[trans.edges])
    ratio <- originalsum / newsum
    res$edge.length[trans.edges] <- res$edge.length[trans.edges] * ratio
  }

  return(res)
}

##############################################################################
#' treeTrans
#'
#' A function that transforms a tree, or a local part of a tree, according to lambda, kappa, delta, or a local rate.
#' @param tree A tree of class phylo
#' @param param The transformation applied to the tree, either "lambda", "kappa", "delta", "rate" or "EB".
#' @param nodes A node number or vector of nodes describing the clade(s) to be transformed.
#' @param tips A vector, or list of vectors, of tip labels definining clade(s) to be transformed
#' @param value The value or vector of values to apply to the tree or parts of the tree. Order corresponds to the order of the elements of nodes or tips.
#' @param rescale Whether or not to rescale the tree to have the same root-to-tip length after transformation. Defaults to TRUE.
#' @export
#' @keywords tree transformation kappa lambda delta rates local rates local transformation
#' @examples
#' transTree(tree, param = "lambda", nodes = 52, value = 0)
#' transTree(tree, param = "rate", nodes = c(52, 91), value = 3)
#' transTree(tree, param = "delta", tips = list(c("dog", "cat", "moose"), c("frog", "salamander", "newt")), value = c(0.3, 2))

treeTrans <- function(tree, param, nodes = "root", tips = NULL, value, rescale = FALSE) {

  if (nodes == "root") {
    nodes <- length(tree$tip.label) + 1
  }

  if (is.null(nodes) & is.null(tips)) {
    stop("Must specify either node(s) or tips")
  }

  if (is.null(tips)) {

    if (length(nodes) != length(value)) {
      stop("Length of nodes and parameter values do not match.")
    }

    if (param == "lambda") {

      for (i in 1:length(nodes)) {
        tree <- localLambda(tree, nodes[i], value[i])
      }

    } else if (param == "kappa") {

      for (i in 1:length(nodes)) {
        tree <- localKappa(tree, nodes[i], value[i], rescale = rescale)
      }

    } else if (param == "delta") {

      for (i in 1:length(nodes)) {
        tree <- localDelta(tree, nodes[i], value[i], rescale = rescale)
      }

    } else if (param == "rate") {

      for (i in 1:length(nodes)) {
        tree <- localRate(tree, nodes[i], value[i])
      }

    } else if (param == "EB") {

      for (i in 1:length(nodes)) {
        tree <- localEB(tree, nodes[i], value[i], rescale = rescale)
      }

    }

  } else if (is.null(nodes)) {
    if (param == "lambda") {

      for (i in 1:length(tips)) {
        node <- getMRCA(tree, tips[[i]])
        tree <- localLambda(tree, node, value[i])
      }

    } else if (param == "kappa") {

      for (i in 1:length(tips)) {
        node <- getMRCA(tree, tips[[i]])
        tree <- localKappa(tree, node, value[i], rescale = rescale)
      }

    } else if (param == "delta") {

      for (i in 1:length(tips)) {
        node <- getMRCA(tree, tips[[i]])
        tree <- localDelta(tree, node, value[i], rescale = rescale)
      }

    } else if (param == "rate") {

      for (i in 1:length(tips)) {
        node <- getMRCA(tree, tips[[i]])
        tree <- localRate(tree, node, value[i])
      }

    }  else if (param == "EB") {

      for (i in 1:length(tips)) {
        node <- getMRCA(tree, tips[[i]])
        tree <- localEB(tree, nodes, value[i], rescale = rescale)
      }

    }


  }
  return(tree)
}

#' plotPhylo
#'
#' A silly little function that makes plotting a tree without tip labels and with
#' an axis easier and quicker.
#' @param tree An object of class phylo
#' @param tips Logical - show tip labels or not?
#' @param nodes TRUE shows all node labels, FALSE supresses node labels (default), or a vecotr of which nodes to highlight.
#' @param nodecex Scaling factor for node labels.
#' @param scale Logical - show the scale bar, or not?
#' @param ... Generic plot arguments (edge.width, edge.cols etc.)
#' @name plotPhylo
#' @export

plotPhylo <- function(tree, tips = FALSE, nodes = NULL, nodecex = NULL, scale = TRUE, ...) {
  plot(tree, show.tip.label = tips, ...)
  if (!is.null(nodes)) {
    if (is.numeric(nodes)) {
      nodelabels(node = nodes, cex = cex)
    } else if (nodes == FALSE) {}
    else {
      nodelabels(cex = nodecex)
    }
  }
  if (scale) {
    axisPhylo()
  }
}

#' plotPosts
#'
#' A function to plot one or more posterior distributions from the logfile of a BayesTraits
#' analysis.
#'
#' @param logfile The name of the trait data file on which BayesTraits was run.
#' @param params A vector containing the name of the parameter(s) that are to be plotted. Can be
#' subsetted from the output of getParams().
#' @param fill The colour for the bars of the histogram. If "count" histogram will be shaded according to count.
#' @param cols The number of columns to plot multiple plots into.
#' @param thinning Thinning parameter for the posterior - defaults to 1 (all samples). 2 uses every second sample, 3 every third and so on.
#' @param burnin The number of generations to remove from the start of the chain as burnin.
#' @keywords plot posterior histogram distribution
#' @export
#' @examples
#' plotPosterior(cool-data.txt, c("Lh", "Alpha 1"))
#' plotPosterior(cool-data.txt, params[c(1:2)])

plotPosts <- function(logfile, pars, fill = "dodgerblue", cols = 2, thinning = 1, burnin = 0) {
  output <- btmcmc(logfile, thinning = thinning, burnin = burnin)

  if (length(pars) == 1) {
    bwidth <- 3.5 * sd(output[ ,pars]) * length(output[ ,pars]) ^ -(1/3)

    if (fill == "count") {
      ret <- ggplot(data.frame(p = output[ ,pars]), aes(x = p, fill = ..count..)) +
        geom_histogram(color = "darkgray", binwidth = bwidth) +
        scale_x_continuous(paste(pars))
    } else {
      ret <- ggplot(data.frame(p = output[ ,pars]), aes(x = p)) +
        geom_histogram(color = "darkgray", binwidth = bwidth, fill = fill) +
        scale_x_continuous(paste(pars))
    }

    return(suppressWarnings(ret))
  } else {
    plots <- list()

    for (i in 1:length(pars)) {
      bwidth <- 3.5 * sd(output[ ,pars[i]]) * length(output[ ,pars[i]]) ^ -(1/3)

      if (bwidth == 0) {
        bwidth <- 1
      }

      plots[[i]] <- ggplot(data.frame(p = output[ ,pars[i]]), aes(x = p)) +
        geom_histogram(color = "darkgray", binwidth = bwidth, fill = fill) +
        scale_x_continuous(paste(pars[i]))
    }

    return(suppressWarnings(multiplot(plotlist = plots, cols = cols)))
  }
}

#' summariseModelString
#'
#' Standardises the model string output from an RJ analysis, and returns a list of two dataframes.
#' One of these gives the frequency of each unique model and the parameter composition of it, and
#' the other details the proportion of times each pair of parameters are locked to the same value.
#' This currently doesn't care whether the parameters are fixed to be the same, or whether they are
#' both zero - just that they are both the same.
#' @param logfile The name of the logfile resulting from an RJ BayesTraits model.
#' @param thinning Thinning parameter for the posterior - defaults to 1 (all samples). 2 uses every second sample, 3 every third and so on.
#' @param burnin The number of generations to remove from the start of the chain as burnin.
#' @name summariseModelString
#' @export

summariseModelString <- function(logfile, thinning = 1, burnin = 0) {
  # get model strings
  output <- btmcmc(logfile, thinning = thinning)
  modstr <- output[ ,"Model.string"]

  # convert to a matrix.
  modstr <- gsub("'", "", modstr)
  modstr <- strsplit(modstr, " ")
  modstr <- matrix(unlist(modstr), ncol = length(modstr[[1]]), byrow = TRUE)

  if (any(colnames(output) == "Dep...InDep")) {
    pars <- colnames(output)[c((which(colnames(output) =="Model.string") + 1)
                               : (which(colnames(output) =="Model.string") + ncol(modstr)) + 1)]
  } else {
    pars <- colnames(output)[c((which(colnames(output) =="Model.string") + 1)
                               : (which(colnames(output) =="Model.string") + ncol(modstr)))]
  }

  if (any(pars == "Dep...InDep")) {
    pars[pars == "Dep...InDep"] <- "I.ID"
  }

  zerotable <- matrix(nrow = ncol(modstr), ncol = 2)
  rownames(zerotable) <- pars
  colnames(zerotable) <- c("frequency", "prob")

  for (i in 1:nrow(zerotable)) {
    zerotable[i, 1] <- sum(modstr[ ,i] == "Z")
    zerotable[i, 2] <- sum(modstr[ ,i] == "Z") / nrow(modstr)
  }

  # work out IDs.
  mods <- list()
  full.mods <- list()

  for (i in 1:nrow(modstr)) {
    ids <- list()

    for (j in 1:ncol(modstr)) {
      ids[[j]] <- sum(2 ^ (which(modstr[i, ] == modstr[i, j])))

      if (modstr[i, j] == "Z") {
        ids[[j]] <- paste0(ids[[j]], "Z")
      }

    }

    mods[[i]] <- unlist(unique(ids))
    full.mods[[i]] <- unlist(ids)
  }

  mods.cf <- mods

  for (i in 1:length(mods.cf)) {
    mods.cf[[i]] <- paste(mods.cf[[i]], collapse = "-")
  }

  full.mods <- lapply(unique(full.mods), setNames, nm = pars)
  names(full.mods) <- unlist(unique(mods.cf))
  res <- matrix(nrow = length(unique(mods)), ncol = max(sapply(mods, length)) + 4)
  colnames(res) <- c("id", "freq", "prop", "Z", paste0("g", c(1:max(sapply(mods, length)))))


  res[ ,"id"] <- names(full.mods)
  res[ ,"freq"] <- table(unlist(mods.cf))
  res[ ,"prop"] <- table(unlist(mods.cf)) / length(mods)

  for (i in 1:nrow(res)) {
    mod.conf <-  full.mods[names(full.mods) == res[i, "id"]][[1]]
    # col correct fits models to the correct column and is adjusted if the Z column is used.
    col.correct <- 4

    for (j in 1:length(strsplit(res[i, "id"], "-")[[1]])) {
      piece <- strsplit(res[i, "id"], "-")[[1]][j]
      group <- which(mod.conf == piece)

      if (grepl("Z", piece)) {
        res[i, "Z"] <- paste(names(group), collapse = "+")
        col.correct <- 3
      } else {
        res[i, (col.correct + j)] <- paste(names(group), collapse = "+")
      }
    }

  }

  # sort res based on frequency
  res <- data.frame(res)
  res$freq <- as.numeric(as.character(res$freq))
  res <- res[base::order(res$freq, decreasing = TRUE), ]
  rownames(res) <- c(1:nrow(res))

  # The last column may be all NA (since the colnum calculation doesn't account for Z)
  # so drop columns until it is not.
  while (all(is.na(res[ , length(res)]))) {
    res <- res[ ,c(1:length(res)-1)]
  }


  pairwise <- matrix(ncol = length(pars), nrow = length(pars), "-")
  rownames(pairwise) <- colnames(pairwise) <- pars
  pairwise.f <- pairwise
  pairwise.p <- pairwise
  pairwise.f.nz <- pairwise
  pairwise.p.nz <- pairwise
  pairwise.f.jz <- pairwise
  pairwise.p.jz <- pairwise

  pairs <- combn(pars, 2)

  for (i in 1:ncol(pairs)) {
    tot <- 0
    totnz <- 0
    totz <- 0

    for (j in 1:length(full.mods)) {
      pars.tmp <- which(names(full.mods[[j]]) %in% pairs[ ,i])

      if (full.mods[[j]][pars.tmp[1]] == full.mods[[j]][pars.tmp[2]]) {

        tot <- tot + res$freq[which(res$id == names(full.mods)[j])]

        if (!grepl("Z", full.mods[[j]][pars.tmp[1]])) {
          totnz <- totnz + res$freq[which(res$id == names(full.mods)[j])]
        }

        if (grepl("Z", full.mods[[j]][pars.tmp[1]])) {
          totz <- totz + res$freq[which(res$id == names(full.mods)[j])]
        }
      }

    }
    row <- which(rownames(pairwise) == pairs[ ,i][1])
    col <- which(colnames(pairwise) == pairs[ ,i][2])
    pairwise.f[row, col] <- tot
    pairwise.p[row, col] <- tot / length(mods)
    pairwise.f.nz[row, col] <- totnz
    pairwise.p.nz[row, col] <- totnz / length(mods)
    pairwise.f.jz[row, col] <- totz
    pairwise.p.jz[row, col] <- totz / length(mods)
  }

  pw.freq <- list(data.frame(pairwise.f), data.frame(pairwise.f.nz), data.frame(pairwise.f.jz))
  names(pw.freq) <- c("pairwise.all", "pairwise.nozero", "pairwise.justzero")
  pw.prob <- list(data.frame(pairwise.p), data.frame(pairwise.p.nz), data.frame(pairwise.p.jz))
  names(pw.prob) <- c("pairwise.all", "pairwise.nozero", "pairwise.justzero")

  ret <- list(res, zerotable, pw.freq, pw.prob)
  names(ret) <- c("models", "zero.params", "parameters.frequency", "parameters.probability")

  return(ret)
}

#' viewLogfile
#'
#' A simple function that shows the logfile.
#' @param logfile The name of the logfile.
#' @param n The number of rows of the logfile to view (defaults to the whole file)
#' @param thinning Thinning parameter for the posterior - defaults to 1 (all samples). 2 uses every second sample, 3 every third and so on.
#' @export

viewLogfile <- function(logfile, n = "max", thinning = 1, burnin = 0) {

  if (n == "max") {
    out <- btmcmc(logfile, thinning = thinning, burnin = burnin)
  } else {
    out <- head(btmcmc(logfile, thinning = thinning, burnin = burnin), n)
  }

  return(out)
}
